
[container]
name = "invokeai"

welcome_msg = '''
Run once
  > su user
  > cd

  > export INVOKEAI_ROOT=/home/user/invokeai
  > . /home/user/invokeai/.venv/bin/activate
  > pip install 'xformers~=0.0.22'
  > pip install triton
  > python -m xformers.info output

  > pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

Run
  > su user
  > cd
  > export INVOKEAI_ROOT=/home/user/invokeai
  > . /home/user/invokeai/.venv/bin/activate
  > invokeai-web --host 127.0.0.1
  > # /home/user/invokeai/invoke.sh <<<'1 '

and open a browser to http://localhost:9090

Also ensure /home/user/.local/bin is on your PATH
  > export PATH=$PATH:/home/user/.local/bin
  > rsync -av $(find /j/downloads -iname '*.safetensors' -print) /mnt/scratch/containers/invokeai/home/user/addtl-models ; ls -alh /j/downloads /mnt/scratch/containers/invokeai/home/user/addtl-models

Also test for that one .so file we need to replace via

  > python -c 'from patchmatch import patch_match'
  > python -c 'import torch ; print("GPU detected: ", torch.cuda.is_available())'

  > find /home/user/py-env -iname '*libgomp*so*'
  > find /home/user/.local/lib/python3.10/site-packages/torch -iname '*libgomp*so*'
  > cp /path/to/libgomp-a34b3233.so.1 /path/to/_ORIGINAL_libgomp-a34b3233.so.1
  > rm /path/to/libgomp-a34b3233.so.1
  > ln -s /usr/lib/libgomp.so.1 /path/to/libgomp-a34b3233.so.1

  > sudo ldconfig
  > python -m pip install --user torch torchvision torchaudio pypatchmatch

'''

runtime_hint = "arch-chroot"

# external scratch disk
disk_partuuids = [
  "e08214f5-cfc5-4252-afee-505dfcd23808"
]

part_subfolder = "containers/invokeai"

# If root FS is empty or install flag missing, all of these are run as root.
install_setup_cmds = [
  # By default the tarball has a root.x86_64/ folder which we want the contents of placed at {container_root_dir}
  "wget -qO- 'http://mirror.adectra.com/archlinux/iso/2023.05.03/archlinux-bootstrap-x86_64.tar.gz' | tar xvz -C '{container_root_dir}' --strip-components=1",

  # Arch will need a good mirror list to install packages with
  "cp /etc/pacman.d/mirrorlist '{container_root_dir}'/etc/pacman.d/mirrorlist",

  # Enable multilib!
  "SH_IN_CONTAINER: echo '[multilib]' >> /etc/pacman.conf",
  "SH_IN_CONTAINER: echo 'Include = /etc/pacman.d/mirrorlist' >> /etc/pacman.conf",
  # Turn off signature checks
  "SH_IN_CONTAINER: sed -i \"s/SigLevel.*=.*/SigLevel = Never/g\" /etc/pacman.conf",
  # Turn off space check
  "SH_IN_CONTAINER: sed -i \"s/^CheckSpace.*/#CheckSpace/g\" /etc/pacman.conf",

  # Steam needs utf-8 locale
  "SH_IN_CONTAINER: echo 'en_US.UTF-8 UTF-8' >> /etc/locale.gen",
  "SH_IN_CONTAINER: locale-gen",
  "SH_IN_CONTAINER: echo 'LANG=\"en_US.UTF-8\"' > /etc/locale.conf",

  "SH_IN_CONTAINER: pacman-key --init",
  "SH_IN_CONTAINER: pacman -S archlinux-keyring",
  "SH_IN_CONTAINER: pacman -Syu --noconfirm",

  # Now install packages!
  "SH_IN_CONTAINER: pacman -Sy --noconfirm sudo vim git base-devel python python-pip nvidia cuda opencl-nvidia ",

  # Setup user 'user'
  "SH_IN_CONTAINER: useradd -m -G games,render,input,video,users,dbus,wheel user",
  "SH_IN_CONTAINER: echo \"%wheel ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/enablewheel",

  # We need python 3.10 which is in the AUR
  "SH_IN_CONTAINER: cd /opt ; git clone https://aur.archlinux.org/yay-git.git ; chown -R user:user /opt/yay-git",
  "SH_IN_CONTAINER: sudo -u user sh -c \"cd /opt/yay-git ; makepkg -si --noconfirm \"",
  "SH_IN_CONTAINER: sudo -u user sh -c \"yay -Sy --noconfirm python310 \"",
  "SH_IN_CONTAINER: rm /usr/bin/python3 ; ln -s /usr/bin/python3.10 /usr/bin/python3 ",

  # Finally install InvokeAI
  "SH_IN_CONTAINER: sudo -u user python -m ensurepip",
  "SH_IN_CONTAINER: sudo -u user mkdir -p /home/user/py-env",
  "SH_IN_CONTAINER: sudo -u user sh -c 'echo export PYTHONPATH=/home/user/py-env >> ~/.bashrc ; echo export PATH=/home/user/invokeai/.venv/bin/:\\$PATH >> ~/.bashrc'",
  "SH_IN_CONTAINER: sudo -u user python -m pip install --target=/home/user/py-env \"InvokeAI[xformers]\" --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117",

  # Addtl packages for GPU
  "SH_IN_CONTAINER: sudo -u user sh -c \"yay -Sy --noconfirm xf86-video-nouveau stable-diffusion-ui python-opencv opencv \"",
  "SH_IN_CONTAINER: cd /usr/lib/pkgconfig/ ; ln -sf opencv4.pc opencv.pc ", # For pip install below
  "SH_IN_CONTAINER: sudo -u user python -m pip install --target=/home/user/py-env torch torchvision torchaudio pypatchmatch",


]

nspawn_addtl_args = [
  "--capability=all",
  # "--capability=CAP_SYS_ADMIN",
  "--bind=/run/user/1000:/run/user/1000",
  "--bind=/var/lib/dbus",
  "--bind=/dev/dri",
  "--bind=/dev/snd",
  "--bind=/tmp",
  "--bind=/dev/nvidia0",
  "--bind=/dev/nvidia1",
  "--bind=/dev/nvidiactl",
  "--bind=/dev/nvidia-modeset",
  "--bind=/dev/nvidia-uvm",
  "--bind=/dev/nvidia-uvm-tools",
  "--bind=/dev/tty2", # used when running from framebuffer to allocate xorg stuffs
  "--user=user", # exec as user user we setup before, we expect it's ID to match our GUI user's ID (1000)
  "--"
]

