
[container]
name = "llms-2024"

welcome_msg = '''
Run once
  > su user
  > cd
  > ollama serve &
  > ollama run llama2
  > ollama run llama2:13b
  > ollama run vicuna:33b
  # See https://ollama.com/library/vicuna/tags

'''

runtime_hint = "arch-chroot"

# external scratch disk
disk_partuuids = [
  "e08214f5-cfc5-4252-afee-505dfcd23808"
]

part_subfolder = "containers/llms-2024"

# If root FS is empty or install flag missing, all of these are run as root.
install_setup_cmds = [
  # By default the tarball has a root.x86_64/ folder which we want the contents of placed at {container_root_dir}
  "wget -qO- 'http://mirror.adectra.com/archlinux/iso/2024.02.01/archlinux-bootstrap-x86_64.tar.gz' | tar xvz -C '{container_root_dir}' --strip-components=1",

  # Arch will need a good mirror list to install packages with
  "cp /etc/pacman.d/mirrorlist '{container_root_dir}'/etc/pacman.d/mirrorlist",

  # Enable multilib!
  "SH_IN_CONTAINER: echo '[multilib]' >> /etc/pacman.conf",
  "SH_IN_CONTAINER: echo 'Include = /etc/pacman.d/mirrorlist' >> /etc/pacman.conf",
  # Turn off signature checks
  "SH_IN_CONTAINER: sed -i \"s/SigLevel.*=.*/SigLevel = Never/g\" /etc/pacman.conf",
  # Turn off space check
  "SH_IN_CONTAINER: sed -i \"s/^CheckSpace.*/#CheckSpace/g\" /etc/pacman.conf",

  # Steam needs utf-8 locale
  "SH_IN_CONTAINER: echo 'en_US.UTF-8 UTF-8' >> /etc/locale.gen",
  "SH_IN_CONTAINER: locale-gen",
  "SH_IN_CONTAINER: echo 'LANG=\"en_US.UTF-8\"' > /etc/locale.conf",

  "SH_IN_CONTAINER: pacman-key --init",
  "SH_IN_CONTAINER: pacman -S archlinux-keyring",
  "SH_IN_CONTAINER: pacman -Syu --noconfirm",

  # Now install packages!
  "SH_IN_CONTAINER: pacman -Sy --noconfirm sudo vim git base-devel python python-pip nvidia cuda opencl-nvidia ",

  # Setup user 'user'
  "SH_IN_CONTAINER: useradd -m -G games,render,input,video,users,dbus,wheel user",
  "SH_IN_CONTAINER: echo \"%wheel ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/enablewheel",

  # We need python 3.10 which is in the AUR
  "SH_IN_CONTAINER: cd /opt ; git clone https://aur.archlinux.org/yay-git.git ; chown -R user:user /opt/yay-git",
  "SH_IN_CONTAINER: sudo -u user sh -c \"cd /opt/yay-git ; makepkg -si --noconfirm \"",
  "SH_IN_CONTAINER: sudo -u user sh -c \"yay -Sy --noconfirm python310 \"",
  "SH_IN_CONTAINER: rm /usr/bin/python3 ; ln -s /usr/bin/python3.10 /usr/bin/python3 ",

  # Addtl packages for GPU
  "SH_IN_CONTAINER: sudo -u user sh -c \"yay -Sy --noconfirm xf86-video-nouveau stable-diffusion-ui python-opencv opencv \"",
  "SH_IN_CONTAINER: cd /usr/lib/pkgconfig/ ; ln -sf opencv4.pc opencv.pc ", # For pip install below
  "SH_IN_CONTAINER: sudo -u user python -m pip install --user torch torchvision torchaudio pypatchmatch",

  # Finally install Ollama & other llm runtimes!
  "SH_IN_CONTAINER: sudo -u user python -m ensurepip",
  "SH_IN_CONTAINER: sudo curl -L https://ollama.com/download/ollama-linux-amd64 -o /usr/bin/ollama",
  "SH_IN_CONTAINER: sudo chmod +x /usr/bin/ollama",

]

nspawn_addtl_args = [
  "--capability=all",
  # "--capability=CAP_SYS_ADMIN",
  "--bind=/run/user/1000:/run/user/1000",
  "--bind=/var/lib/dbus",
  "--bind=/dev/dri",
  "--bind=/dev/snd",
  "--bind=/tmp",
  "--bind=/dev/nvidia0",
  "--bind=/dev/nvidia1",
  "--bind=/dev/nvidiactl",
  "--bind=/dev/nvidia-modeset",
  "--bind=/dev/nvidia-uvm",
  "--bind=/dev/nvidia-uvm-tools",
  "--bind=/dev/tty2", # used when running from framebuffer to allocate xorg stuffs
  "--user=user", # exec as user user we setup before, we expect it's ID to match our GUI user's ID (1000)
  "--"
]

